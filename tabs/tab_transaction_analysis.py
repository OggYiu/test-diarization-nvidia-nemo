"""
Tab: Transaction Analysis
Analyze two transcriptions to identify stock transactions with confidence scoring
"""

import traceback
from typing import Literal, Optional
import gradio as gr

from pydantic import BaseModel, Field
from langchain_ollama import ChatOllama


# Common model options
MODEL_OPTIONS = [
    "qwen3:32b",
    "gpt-oss:20b",
    "gemma3-27b",
    "deepseek-r1:32b",
    "deepseek-r1:70b",
]

DEFAULT_MODEL = MODEL_OPTIONS[0]
DEFAULT_OLLAMA_URL = "http://localhost:11434"


# Pydantic models for structured transaction output
class Transaction(BaseModel):
    """Represents a single transaction"""
    
    transaction_type: Literal["buy", "sell", "queue"] = Field(
        description="The type of transaction identified: buy, sell, or queue"
    )
    
    confidence_score: float = Field(
        ge=0.0, 
        le=2.0,
        description="Confidence score from 0 to 2. 0=not sure at all, 1=moderately confident, 2=very confident"
    )
    
    stock_code: Optional[str] = Field(
        default=None,
        description="The stock code/number identified in the conversation"
    )
    
    stock_name: Optional[str] = Field(
        default=None,
        description="The stock name identified in the conversation"
    )
    
    quantity: Optional[str] = Field(
        default=None,
        description="The quantity/amount of stocks in the transaction"
    )
    
    price: Optional[str] = Field(
        default=None,
        description="The price mentioned in the transaction"
    )
    
    explanation: str = Field(
        description="Detailed explanation of why this transaction type and confidence score were assigned"
    )


class TransactionAnalysisResult(BaseModel):
    """Complete analysis result with multiple transactions"""
    
    transactions: list[Transaction] = Field(
        default_factory=list,
        description="List of all transactions identified in the conversation. Empty list if no transactions found."
    )
    
    transcription_comparison: str = Field(
        description="Comparison of the two transcriptions and how they differ"
    )
    
    overall_summary: str = Field(
        description="Overall summary of the conversation and all transactions identified"
    )


DEFAULT_SYSTEM_MESSAGE = """ä½ æ˜¯ä¸€ä½ç²¾é€šç²µèªçš„é¦™æ¸¯è‚¡å¸‚åˆ†æå¸«ï¼Œå°ˆé–€åˆ†æé›»è©±éŒ„éŸ³ä¸­çš„è‚¡ç¥¨äº¤æ˜“ã€‚

ä½ çš„ä»»å‹™æ˜¯ï¼š
1. æ¯”è¼ƒå…©å€‹ä¸åŒSTTæ¨¡å‹ç”Ÿæˆçš„è½‰éŒ„æ–‡å­—
2. **é‡è¦ï¼šæª¢æŸ¥è‚¡ç¥¨åƒè€ƒè³‡æ–™ä¸­åˆ—å‡ºçš„æ‰€æœ‰è‚¡ç¥¨**ï¼Œè­˜åˆ¥å°è©±ä¸­æ˜¯å¦æåŠé€™äº›è‚¡ç¥¨
3. è­˜åˆ¥å°è©±ä¸­çš„æ‰€æœ‰è‚¡ç¥¨äº¤æ˜“ï¼ˆè²·å…¥buyã€è³£å‡ºsellã€æ’éšŠqueueï¼‰
4. å°è©±ä¸­å¯èƒ½æœ‰å¤šå€‹äº¤æ˜“ã€ä¸€å€‹äº¤æ˜“ã€æˆ–æ²’æœ‰äº¤æ˜“
5. ç‚ºæ¯å€‹äº¤æ˜“è©•ä¼°ç½®ä¿¡åº¦ï¼ˆ0-2åˆ†ï¼‰ï¼š
   - **0åˆ†ï¼šå®Œå…¨ä¸ç¢ºå®š** - åªæ˜¯è¨è«–ã€æ²’æœ‰æ˜ç¢ºä¸‹å–®æ„åœ–
   - **1åˆ†ï¼šæœ‰ä¸€å®šè­‰æ“šä½†ä¸å®Œå…¨ç¢ºå®š** - æåˆ°äº¤æ˜“ä½†æ²’æœ‰å®Œæ•´ç¢ºèªæµç¨‹
   - **2åˆ†ï¼šéå¸¸ç¢ºå®šæœ‰äº¤æ˜“ç™¼ç”Ÿ** - åˆ¸å•†é‡è¤‡ä¸‹å–®è³‡æ–™ï¼Œå®¢æˆ¶æ˜ç¢ºç¢ºèª
6. æå–æ¯å€‹äº¤æ˜“çš„ç´°ç¯€ï¼ˆè‚¡ç¥¨ä»£è™Ÿã€è‚¡ç¥¨åç¨±ã€æ•¸é‡ã€åƒ¹æ ¼ç­‰ï¼‰
7. **ä½¿ç”¨è‚¡ç¥¨åƒè€ƒè³‡æ–™ä¾†åŒ¹é…å’Œé©—è­‰å°è©±ä¸­æåˆ°çš„è‚¡ç¥¨ä»£è™Ÿå’Œåç¨±**

# åˆ¤æ–·æº–å‰‡
- åˆ¸å•†å¿…é ˆé‡è¤‡ä¸‹å–®è³‡æ–™è®“å®¢æˆ¶ç¢ºèªï¼Œæ‰ç®—æ˜¯çœŸæ­£çš„ä¸‹å–®ï¼ˆconfidence_score: 2ï¼‰
- å¦‚æœæœ‰æåˆ°äº¤æ˜“ç´°ç¯€ä½†ç¼ºå°‘ç¢ºèªæ­¥é©Ÿï¼ˆconfidence_score: 1ï¼‰
- å¦‚æœåªæ˜¯è¨è«–è€Œæ²’æœ‰ä¸‹å–®æ„åœ–ï¼ˆconfidence_score: 0ï¼Œæˆ–ä¸åˆ—ç‚ºäº¤æ˜“ï¼‰
- ä¸€å€‹å°è©±ä¸­å¯èƒ½åŒ…å«å¤šå€‹ä¸åŒçš„äº¤æ˜“
- å…©å€‹è½‰éŒ„æ–‡å­—å¯èƒ½æœ‰å·®ç•°ï¼Œè«‹ç¶œåˆåˆ¤æ–·
- **ä»”ç´°å°ç…§è‚¡ç¥¨åƒè€ƒè³‡æ–™ä¸­çš„æ‰€æœ‰è‚¡ç¥¨ï¼Œç¢ºä¿æ²’æœ‰éºæ¼ä»»ä½•æåŠçš„è‚¡ç¥¨**

# ç²µèªè¡“èªå’Œç°¡ç¨±
- è½® = çª©è¼ª
- æ²½/å­¤ = è³£å‡º
- è²·å…¥/å…¥ = è²·å…¥

# å¸¸è¦‹STTèª¤å·®
- ã€Œç™¾ã€å¯èƒ½æ˜¯ã€Œå…«ã€ï¼šä¾‹å¦‚ã€Œä¸€ç™¾ä¸€ä¸‰å…«ã€æ‡‰è©²æ˜¯ã€Œä¸€å…«ä¸€ä¸‰å…«ã€ï¼ˆ18138ï¼‰
- ä½¿ç”¨è‚¡ç¥¨åƒè€ƒè³‡æ–™ä¾†ä¿®æ­£å¯èƒ½çš„STTèª¤å·®

# è¼¸å‡ºæ ¼å¼
**å¿…é ˆ**è¿”å›æœ‰æ•ˆçš„JSONæ ¼å¼ï¼Œåš´æ ¼éµå®ˆä»¥ä¸‹çµæ§‹ï¼š

{
  "transactions": [
    {
      "transaction_type": "buy",  // å¿…é ˆæ˜¯ "buy", "sell", æˆ– "queue"
      "confidence_score": 2.0,    // å¿…é ˆæ˜¯æ•¸å­— 0.0-2.0ï¼Œä¸èƒ½æ˜¯å­—ç¬¦ä¸²
      "stock_code": "0700",
      "stock_name": "é¨°è¨Š",
      "quantity": "1000",
      "price": "350",
      "explanation": "å®¢æˆ¶è¦æ±‚è²·å…¥é¨°è¨Š0700ï¼Œåˆ¸å•†é‡è¤‡ç¢ºèªäº†è‚¡ç¥¨ä»£è™Ÿã€æ•¸é‡å’Œåƒ¹æ ¼ï¼Œå®¢æˆ¶æ˜ç¢ºç¢ºèªï¼Œå› æ­¤ç½®ä¿¡åº¦ç‚º2åˆ†"
    }
  ],
  "transcription_comparison": "å…©å€‹è½‰éŒ„çš„æ¯”è¼ƒèªªæ˜...",
  "overall_summary": "æ•´é«”æ‘˜è¦...ï¼ˆå¿…é ˆåŒ…å«å°è‚¡ç¥¨åƒè€ƒè³‡æ–™ä¸­æ‰€æœ‰è‚¡ç¥¨çš„æª¢æŸ¥çµæœï¼‰"
}

**é‡è¦æç¤ºï¼š**
- confidence_score å¿…é ˆæ˜¯æ•¸å­—ï¼ˆfloatï¼‰ï¼Œä¸èƒ½æ˜¯å­—ç¬¦ä¸²
- å¦‚æœæœ‰æ˜ç¢ºçš„äº¤æ˜“ç¢ºèªï¼Œconfidence_score æ‡‰è©²æ˜¯ 1.5 æˆ– 2.0ï¼Œä¸è¦ç¸½æ˜¯çµ¦ 0
- explanation å­—æ®µå¿…é ˆè©³ç´°èªªæ˜ç‚ºä»€éº¼çµ¦é€™å€‹ç½®ä¿¡åº¦åˆ†æ•¸
- overall_summary å¿…é ˆèªªæ˜æ˜¯å¦æª¢æŸ¥äº†è‚¡ç¥¨åƒè€ƒè³‡æ–™ä¸­çš„æ‰€æœ‰è‚¡ç¥¨
"""


def analyze_transactions(
    transcription1: str,
    transcription2: str,
    stock_reference: str,
    model: str,
    ollama_url: str,
    system_message: str,
    temperature: float,
) -> tuple[str, str]:
    """
    Analyze two transcriptions to identify transactions
    
    Returns:
        tuple: (summary_result, json_result)
    """
    try:
        # Validate inputs
        if not transcription1.strip() and not transcription2.strip():
            error_msg = "âŒ éŒ¯èª¤ï¼šè«‹è‡³å°‘æä¾›ä¸€å€‹è½‰éŒ„æ–‡å­—"
            return (error_msg, "")
        
        if not model or not model.strip():
            error_msg = "âŒ éŒ¯èª¤ï¼šè«‹æŒ‡å®šæ¨¡å‹åç¨±"
            return (error_msg, "")
        
        if not ollama_url or not ollama_url.strip():
            error_msg = "âŒ éŒ¯èª¤ï¼šè«‹æŒ‡å®š Ollama URL"
            return (error_msg, "")
        
        # Build the prompt
        stock_ref_text = stock_reference.strip() if stock_reference.strip() else "ï¼ˆç„¡æä¾›ï¼‰"
        prompt = f"""è«‹åˆ†æä»¥ä¸‹å…©å€‹STTæ¨¡å‹ç”Ÿæˆçš„è½‰éŒ„æ–‡å­—ï¼Œè­˜åˆ¥æ˜¯å¦æœ‰è‚¡ç¥¨äº¤æ˜“ç™¼ç”Ÿã€‚

## è½‰éŒ„æ–‡å­— 1ï¼š
{transcription1}

## è½‰éŒ„æ–‡å­— 2ï¼š
{transcription2}

## è‚¡ç¥¨åƒè€ƒè³‡æ–™ï¼š
{stock_ref_text}

**é‡è¦ä»»å‹™ï¼š**
1. è«‹ä»”ç´°æª¢æŸ¥å°è©±ä¸­æ˜¯å¦æåŠè‚¡ç¥¨åƒè€ƒè³‡æ–™ä¸­åˆ—å‡ºçš„**æ‰€æœ‰è‚¡ç¥¨**
2. å°æ–¼æ¯å€‹æåŠçš„è‚¡ç¥¨ï¼Œåˆ¤æ–·æ˜¯å¦æœ‰äº¤æ˜“ç™¼ç”Ÿï¼ˆè²·å…¥/è³£å‡º/æ’éšŠï¼‰
3. ä½¿ç”¨è‚¡ç¥¨åƒè€ƒè³‡æ–™ä¾†é©—è­‰å’Œä¿®æ­£è½‰éŒ„æ–‡å­—ä¸­å¯èƒ½çš„è‚¡ç¥¨ä»£è™Ÿæˆ–åç¨±éŒ¯èª¤
4. åœ¨ overall_summary ä¸­æ˜ç¢ºèªªæ˜æª¢æŸ¥äº†å“ªäº›è‚¡ç¥¨ï¼Œå“ªäº›è‚¡ç¥¨åœ¨å°è©±ä¸­è¢«æåŠï¼Œå“ªäº›æ²’æœ‰è¢«æåŠ

è«‹æ ¹æ“šä»¥ä¸Šè³‡æ–™ï¼Œä½¿ç”¨çµæ§‹åŒ–æ ¼å¼è¿”å›åˆ†æçµæœã€‚
"""
        
        # Initialize the LLM with structured output
        chat_llm = ChatOllama(
            model=model,
            base_url=ollama_url,
            temperature=temperature,
            format="json",  # Request JSON format
        )
        
        # Prepare messages
        messages = [
            ("system", system_message),
            ("human", prompt),
        ]
        
        # Get response
        print(f"ğŸ” Analyzing transactions with {model}...")
        resp = chat_llm.invoke(messages)
        
        # Extract content
        try:
            response_content = getattr(resp, "content", str(resp))
        except Exception:
            response_content = str(resp)
        
        # Try to parse as structured output
        try:
            import json
            result_dict = json.loads(response_content)
            
            # Debug: Print raw JSON response
            print("="*60)
            print("ğŸ” DEBUG: Raw LLM JSON Response:")
            print(json.dumps(result_dict, indent=2, ensure_ascii=False))
            print("="*60)
            
            # Extract the new structure
            transactions = result_dict.get("transactions", [])
            comparison = result_dict.get("transcription_comparison", "")
            overall_summary = result_dict.get("overall_summary", "")
            
            # Create formatted summary result for all transactions
            summary_result = f"""ğŸ“Š äº¤æ˜“åˆ†æçµæœ
{'='*50}

ğŸ“‹ ç¸½å…±è­˜åˆ¥åˆ° {len(transactions)} å€‹äº¤æ˜“

"""
            
            if len(transactions) == 0:
                summary_result += "âŒ æ²’æœ‰è­˜åˆ¥åˆ°ä»»ä½•äº¤æ˜“\n\n"
            else:
                for idx, tx in enumerate(transactions, 1):
                    tx_type = tx.get("transaction_type", "none")
                    tx_conf = tx.get("confidence_score", 0.0)
                    tx_code = tx.get("stock_code", "") or "N/A"
                    tx_name = tx.get("stock_name", "") or "N/A"
                    tx_qty = tx.get("quantity", "") or "N/A"
                    tx_price = tx.get("price", "") or "N/A"
                    tx_exp = tx.get("explanation", "")
                    
                    summary_result += f"""{'â”€'*50}
äº¤æ˜“ #{idx}
{'â”€'*50}
ğŸ”– äº¤æ˜“é¡å‹: {tx_type}
â­ ç½®ä¿¡åº¦åˆ†æ•¸: {tx_conf} / 2.0
ğŸ“ˆ è‚¡ç¥¨ä»£è™Ÿ: {tx_code}
ğŸ¢ è‚¡ç¥¨åç¨±: {tx_name}
ğŸ”¢ æ•¸é‡: {tx_qty}
ğŸ’° åƒ¹æ ¼: {tx_price}

ğŸ“ åˆ†æèªªæ˜:
{tx_exp}

"""
            
            summary_result += f"""{'='*50}
ğŸ”„ è½‰éŒ„æ¯”è¼ƒ:
{comparison}

{'='*50}
ğŸ“„ æ•´é«”æ‘˜è¦:
{overall_summary}
"""
            
            # Format JSON result with proper indentation
            json_result = json.dumps(result_dict, indent=2, ensure_ascii=False)
            
            return (summary_result, json_result)
            
        except json.JSONDecodeError:
            # If not valid JSON, return the raw response
            error_msg = f"âš ï¸ æ¨¡å‹è¿”å›éçµæ§‹åŒ–è¼¸å‡ºï¼š\n\n{response_content}"
            return (error_msg, response_content)
        
    except Exception as e:
        error_msg = f"âŒ éŒ¯èª¤: {str(e)}\n\nè©³ç´°ä¿¡æ¯:\n{traceback.format_exc()}"
        return (error_msg, "")


def create_transaction_analysis_tab():
    """Create and return the Transaction Analysis tab"""
    with gr.Tab("ğŸ“Š Transaction Analysis"):
        gr.Markdown(
            """
            ### äº¤æ˜“åˆ†æ - æ¯”è¼ƒå…©å€‹STTè½‰éŒ„ä¸¦è­˜åˆ¥äº¤æ˜“
            ä½¿ç”¨Pydanticçµæ§‹åŒ–è¼¸å‡ºè­˜åˆ¥æ‰€æœ‰è‚¡ç¥¨äº¤æ˜“ï¼ˆè²·å…¥/è³£å‡º/æ’éšŠï¼‰ä¸¦è©•ä¼°ç½®ä¿¡åº¦ï¼ˆ0-2åˆ†ï¼‰
            
            **æ”¯æŒåŠŸèƒ½ï¼š**
            - âœ… è­˜åˆ¥å¤šå€‹äº¤æ˜“ï¼ˆä¸€å€‹å°è©±ä¸­å¯èƒ½æœ‰å¤šç­†äº¤æ˜“ï¼‰
            - âœ… è­˜åˆ¥å–®å€‹äº¤æ˜“
            - âœ… è­˜åˆ¥ç„¡äº¤æ˜“çš„å°è©±
            - âœ… æª¢æŸ¥ä¸¦åˆ†æè‚¡ç¥¨åƒè€ƒè³‡æ–™ä¸­çš„æ‰€æœ‰è‚¡ç¥¨
            - âœ… ä½¿ç”¨è‚¡ç¥¨åƒè€ƒè³‡æ–™ä¾†é©—è­‰å’Œä¿®æ­£STTèª¤å·®
            """
        )
        
        with gr.Row():
            with gr.Column(scale=1):
                gr.Markdown("#### è¼¸å…¥è¨­å®š")
                
                transcription1_box = gr.Textbox(
                    label="è½‰éŒ„æ–‡å­— 1 (STT Model 1)",
                    placeholder="è«‹è¼¸å…¥ç¬¬ä¸€å€‹STTæ¨¡å‹çš„è½‰éŒ„çµæœ...",
                    lines=10,
                )
                
                transcription2_box = gr.Textbox(
                    label="è½‰éŒ„æ–‡å­— 2 (STT Model 2)",
                    placeholder="è«‹è¼¸å…¥ç¬¬äºŒå€‹STTæ¨¡å‹çš„è½‰éŒ„çµæœ...",
                    lines=10,
                )
                
                stock_reference_box = gr.Textbox(
                    label="è‚¡ç¥¨åƒè€ƒè³‡æ–™ (Stock References)",
                    placeholder="ä¾‹å¦‚ï¼š\né¨°è¨Š 0700\né˜¿é‡Œå·´å·´ 9988\næ»™è± 0005",
                    lines=5,
                    info="è¼¸å…¥å¯èƒ½åœ¨å°è©±ä¸­å‡ºç¾çš„è‚¡ç¥¨åç¨±å’Œä»£è™Ÿã€‚LLMå°‡æª¢æŸ¥ä¸¦åˆ†ææ‰€æœ‰åˆ—å‡ºçš„è‚¡ç¥¨ã€‚",
                )
                
                gr.Markdown("#### LLM è¨­å®š")
                
                with gr.Row():
                    model_dropdown = gr.Dropdown(
                        choices=MODEL_OPTIONS,
                        value=DEFAULT_MODEL,
                        label="æ¨¡å‹",
                        allow_custom_value=True,
                    )
                    temperature_slider = gr.Slider(
                        minimum=0.0,
                        maximum=2.0,
                        value=0.3,
                        step=0.1,
                        label="Temperature",
                        info="è¼ƒä½çš„æº«åº¦æœƒè®“çµæœæ›´ç¢ºå®š",
                    )
                
                ollama_url_box = gr.Textbox(
                    label="Ollama URL",
                    value=DEFAULT_OLLAMA_URL,
                    placeholder="http://localhost:11434",
                )
                
                system_message_box = gr.Textbox(
                    label="ç³»çµ±è¨Šæ¯ (System Message)",
                    value=DEFAULT_SYSTEM_MESSAGE,
                    lines=8,
                )
                
                analyze_btn = gr.Button(
                    "ğŸš€ é–‹å§‹åˆ†æäº¤æ˜“",
                    variant="primary",
                    size="lg"
                )
            
            with gr.Column(scale=1):
                gr.Markdown("#### åˆ†æçµæœ")
                
                # Summary Result Textbox (all transactions)
                summary_result_box = gr.Textbox(
                    label="ğŸ“Š å®Œæ•´çµæœæ‘˜è¦ (All Transactions)",
                    lines=15,
                    interactive=False,
                    show_copy_button=True,
                )
                
                # JSON Result Textbox (raw output)
                json_result_box = gr.Textbox(
                    label="ğŸ“‹ Pydantic JSON è¼¸å‡º (JSON Output)",
                    lines=15,
                    interactive=False,
                    show_copy_button=True,
                )
        
        # Connect the button
        analyze_btn.click(
            fn=analyze_transactions,
            inputs=[
                transcription1_box,
                transcription2_box,
                stock_reference_box,
                model_dropdown,
                ollama_url_box,
                system_message_box,
                temperature_slider,
            ],
            outputs=[
                summary_result_box,
                json_result_box,
            ],
        )

