"""
Tab: Transaction Analysis
Analyze two transcriptions to identify stock transactions with confidence scoring
"""

import json
import traceback
from typing import Literal, Optional
import gradio as gr

from pydantic import BaseModel, Field
from langchain_ollama import ChatOllama

# Import centralized model configuration
from model_config import MODEL_OPTIONS, DEFAULT_MODEL, DEFAULT_OLLAMA_URL


# Pydantic models for structured transaction output
class Transaction(BaseModel):
    """Represents a single transaction"""
    
    transaction_type: Literal["buy", "sell", "queue"] = Field(
        description="The type of transaction identified: buy, sell, or queue"
    )
    
    confidence_score: float = Field(
        ge=0.0, 
        le=2.0,
        description="Confidence score from 0 to 2. 0=not sure at all, 1=moderately confident, 2=very confident"
    )
    
    stock_code: Optional[str] = Field(
        default=None,
        description="The stock code/number identified in the conversation"
    )
    
    stock_name: Optional[str] = Field(
        default=None,
        description="The stock name identified in the conversation"
    )
    
    quantity: Optional[str] = Field(
        default=None,
        description="The quantity/amount of stocks in the transaction"
    )
    
    price: Optional[str] = Field(
        default=None,
        description="The price mentioned in the transaction"
    )
    
    explanation: str = Field(
        description="Detailed explanation of why this transaction type and confidence score were assigned"
    )


class TransactionAnalysisResult(BaseModel):
    """Complete analysis result with multiple transactions"""
    
    transactions: list[Transaction] = Field(
        default_factory=list,
        description="List of all transactions identified in the conversation. Empty list if no transactions found."
    )
    
    transcription_comparison: str = Field(
        description="Comparison of the two transcriptions and how they differ"
    )
    
    overall_summary: str = Field(
        description="Overall summary of the conversation and all transactions identified"
    )


DEFAULT_SYSTEM_MESSAGE = """ä½ æ˜¯ä¸€ä½ç²¾é€šç²µèªçš„é¦™æ¸¯è‚¡å¸‚åˆ†æå¸«ï¼Œå°ˆé–€åˆ†æé›»è©±éŒ„éŸ³ä¸­çš„è‚¡ç¥¨äº¤æ˜“ã€‚

ä½ çš„ä»»å‹™æ˜¯ï¼š
1. æ¯”è¼ƒå…©å€‹ä¸åŒSTTæ¨¡å‹ç”Ÿæˆçš„è½‰éŒ„æ–‡å­—
2. **æ ¸å¿ƒä»»å‹™ï¼šé€ä¸€æª¢æŸ¥è‚¡ç¥¨åƒè€ƒè³‡æ–™ä¸­åˆ—å‡ºçš„æ¯ä¸€éš»è‚¡ç¥¨**ï¼Œè­˜åˆ¥å°è©±ä¸­æ˜¯å¦æåŠé€™äº›è‚¡ç¥¨
3. è­˜åˆ¥å°è©±ä¸­çš„æ‰€æœ‰è‚¡ç¥¨äº¤æ˜“ï¼ˆè²·å…¥buyã€è³£å‡ºsellã€æ’éšŠqueueï¼‰
4. å°è©±ä¸­å¯èƒ½æœ‰å¤šå€‹äº¤æ˜“ã€ä¸€å€‹äº¤æ˜“ã€æˆ–æ²’æœ‰äº¤æ˜“
5. ç‚ºæ¯å€‹äº¤æ˜“è©•ä¼°ç½®ä¿¡åº¦ï¼ˆ0-2åˆ†ï¼‰ï¼š
   - **0åˆ†ï¼šå®Œå…¨ä¸ç¢ºå®š** - åªæ˜¯è¨è«–ã€æ²’æœ‰æ˜ç¢ºä¸‹å–®æ„åœ–
   - **1åˆ†ï¼šæœ‰ä¸€å®šè­‰æ“šä½†ä¸å®Œå…¨ç¢ºå®š** - æåˆ°äº¤æ˜“ä½†æ²’æœ‰å®Œæ•´ç¢ºèªæµç¨‹
   - **2åˆ†ï¼šéå¸¸ç¢ºå®šæœ‰äº¤æ˜“ç™¼ç”Ÿ** - åˆ¸å•†é‡è¤‡ä¸‹å–®è³‡æ–™ï¼Œå®¢æˆ¶æ˜ç¢ºç¢ºèª
6. æå–æ¯å€‹äº¤æ˜“çš„ç´°ç¯€ï¼ˆè‚¡ç¥¨ä»£è™Ÿã€è‚¡ç¥¨åç¨±ã€æ•¸é‡ã€åƒ¹æ ¼ç­‰ï¼‰
7. **ä½¿ç”¨è‚¡ç¥¨åƒè€ƒè³‡æ–™ä¾†åŒ¹é…å’Œé©—è­‰å°è©±ä¸­æåˆ°çš„è‚¡ç¥¨ä»£è™Ÿå’Œåç¨±**

# è‚¡ç¥¨åƒè€ƒè³‡æ–™çš„ä½¿ç”¨æ–¹å¼
- **å¿…é ˆé€ä¸€æª¢æŸ¥è‚¡ç¥¨åƒè€ƒè³‡æ–™ä¸­çš„æ¯ä¸€éš»è‚¡ç¥¨**
- æª¢æŸ¥æ¯éš»è‚¡ç¥¨çš„ä»£è™Ÿå’Œåç¨±æ˜¯å¦åœ¨å°è©±ä¸­è¢«æåŠ
- è‚¡ç¥¨åƒè€ƒè³‡æ–™åŒ…å«ä»¥ä¸‹ä¿¡æ¯ï¼š
  * stock_number / stock_name: å¾STTè­˜åˆ¥å‡ºçš„è‚¡ç¥¨ä»£è™Ÿå’Œåç¨±
  * corrected_stock_number / corrected_stock_name: ä¿®æ­£å¾Œçš„æ­£ç¢ºä»£è™Ÿå’Œåç¨±
  * original_word: STTè½‰éŒ„çš„åŸå§‹æ–‡å­—ï¼ˆå¦‚"ä¸€ç™¾ä¸€ä¸‰å…«"ã€"ä¸‰è™Ÿå…«"ã€"é‡‘ç¢Ÿ"ç­‰ï¼‰
  * relevance_score: è‚¡ç¥¨åœ¨å°è©±ä¸­çš„ç›¸é—œåº¦åˆ†æ•¸
- ä½¿ç”¨é€™äº›ä¿¡æ¯ä¾†ï¼š
  * è­˜åˆ¥STTå¯èƒ½çš„èª¤å·®ï¼ˆå¦‚"ä¸€ç™¾ä¸€ä¸‰å…«"å¯¦éš›æ˜¯"18138"ï¼‰
  * é©—è­‰å’Œä¿®æ­£è‚¡ç¥¨åç¨±ï¼ˆå¦‚"é‡‘ç¢Ÿ"å¯¦éš›æ˜¯"é‡‘è¶åœ‹éš›"ï¼‰
  * æ ¹æ“šç›¸é—œåº¦åˆ†æ•¸åˆ¤æ–·è‚¡ç¥¨åœ¨å°è©±ä¸­çš„é‡è¦æ€§
- åœ¨ overall_summary ä¸­æ˜ç¢ºåˆ—å‡ºæ¯éš»è‚¡ç¥¨çš„æª¢æŸ¥çµæœ

# åˆ¤æ–·æº–å‰‡
- åˆ¸å•†å¿…é ˆé‡è¤‡ä¸‹å–®è³‡æ–™è®“å®¢æˆ¶ç¢ºèªï¼Œæ‰ç®—æ˜¯çœŸæ­£çš„ä¸‹å–®ï¼ˆconfidence_score: 2ï¼‰
- å¦‚æœæœ‰æåˆ°äº¤æ˜“ç´°ç¯€ä½†ç¼ºå°‘ç¢ºèªæ­¥é©Ÿï¼ˆconfidence_score: 1ï¼‰
- å¦‚æœåªæ˜¯è¨è«–è€Œæ²’æœ‰ä¸‹å–®æ„åœ–ï¼ˆconfidence_score: 0ï¼Œæˆ–ä¸åˆ—ç‚ºäº¤æ˜“ï¼‰
- ä¸€å€‹å°è©±ä¸­å¯èƒ½åŒ…å«å¤šå€‹ä¸åŒçš„äº¤æ˜“
- å…©å€‹è½‰éŒ„æ–‡å­—å¯èƒ½æœ‰å·®ç•°ï¼Œè«‹ç¶œåˆåˆ¤æ–·
- **ä»”ç´°å°ç…§è‚¡ç¥¨åƒè€ƒè³‡æ–™ä¸­çš„æ‰€æœ‰è‚¡ç¥¨ï¼Œç¢ºä¿æ²’æœ‰éºæ¼ä»»ä½•æåŠçš„è‚¡ç¥¨**

# ç²µèªè¡“èªå’Œç°¡ç¨±
- è½® = çª©è¼ª
- æ²½/å­¤ = è³£å‡º
- è²·å…¥/å…¥ = è²·å…¥

# å¸¸è¦‹STTèª¤å·®
- ã€Œç™¾ã€å¯èƒ½æ˜¯ã€Œå…«ã€ï¼šä¾‹å¦‚ã€Œä¸€ç™¾ä¸€ä¸‰å…«ã€æ‡‰è©²æ˜¯ã€Œ18138ã€
- éŸ³è¿‘å­—èª¤å·®ï¼šä¾‹å¦‚ã€Œé‡‘ç¢Ÿã€å¯¦éš›æ˜¯ã€Œé‡‘è¶ã€
- æ•¸å­—ç°¡ç¨±ï¼šä¾‹å¦‚ã€Œä¸‰è™Ÿå…«ã€å¯èƒ½æ˜¯ã€Œ00038ã€æˆ–ã€Œ00388ã€
- ã€Œå…­å€‹å…­ä¸ƒã€ç­‰æ¨¡ç³Šè¡¨è¿°å¯èƒ½æŒ‡ç‰¹å®šè‚¡ç¥¨ä»£è™Ÿ
- **è‚¡ç¥¨åƒè€ƒè³‡æ–™ä¸­çš„ original_word å­—æ®µæœƒé¡¯ç¤ºSTTçš„åŸå§‹è½‰éŒ„æ–‡å­—**
- **è‚¡ç¥¨åƒè€ƒè³‡æ–™ä¸­çš„ corrected_* å­—æ®µæœƒæä¾›ä¿®æ­£å¾Œçš„æ­£ç¢ºä¿¡æ¯**
- ä½¿ç”¨é€™äº›ä¿¡æ¯ä¾†ç†è§£å’Œé©—è­‰å°è©±ä¸­çš„è‚¡ç¥¨æåŠ

# è¼¸å‡ºæ ¼å¼
**å¿…é ˆ**è¿”å›æœ‰æ•ˆçš„JSONæ ¼å¼ï¼Œåš´æ ¼éµå®ˆä»¥ä¸‹çµæ§‹ï¼š

{
  "transactions": [
    {
      "transaction_type": "buy",  // å¿…é ˆæ˜¯ "buy", "sell", æˆ– "queue"
      "confidence_score": 2.0,    // å¿…é ˆæ˜¯æ•¸å­— 0.0-2.0ï¼Œä¸èƒ½æ˜¯å­—ç¬¦ä¸²
      "stock_code": "0700",
      "stock_name": "é¨°è¨Š",
      "quantity": "1000",
      "price": "350",
      "explanation": "å®¢æˆ¶è¦æ±‚è²·å…¥é¨°è¨Š0700ï¼Œåˆ¸å•†é‡è¤‡ç¢ºèªäº†è‚¡ç¥¨ä»£è™Ÿã€æ•¸é‡å’Œåƒ¹æ ¼ï¼Œå®¢æˆ¶æ˜ç¢ºç¢ºèªï¼Œå› æ­¤ç½®ä¿¡åº¦ç‚º2åˆ†"
    }
  ],
  "transcription_comparison": "å…©å€‹è½‰éŒ„çš„æ¯”è¼ƒèªªæ˜...",
  "overall_summary": "æ•´é«”æ‘˜è¦...ï¼ˆå¿…é ˆåŒ…å«å°è‚¡ç¥¨åƒè€ƒè³‡æ–™ä¸­æ‰€æœ‰è‚¡ç¥¨çš„æª¢æŸ¥çµæœï¼‰"
}

**é‡è¦æç¤ºï¼š**
- confidence_score å¿…é ˆæ˜¯æ•¸å­—ï¼ˆfloatï¼‰ï¼Œä¸èƒ½æ˜¯å­—ç¬¦ä¸²
- å¦‚æœæœ‰æ˜ç¢ºçš„äº¤æ˜“ç¢ºèªï¼Œconfidence_score æ‡‰è©²æ˜¯ 1.5 æˆ– 2.0ï¼Œä¸è¦ç¸½æ˜¯çµ¦ 0
- explanation å­—æ®µå¿…é ˆè©³ç´°èªªæ˜ç‚ºä»€éº¼çµ¦é€™å€‹ç½®ä¿¡åº¦åˆ†æ•¸
- overall_summary **å¿…é ˆé€ä¸€åˆ—å‡ºè‚¡ç¥¨åƒè€ƒè³‡æ–™ä¸­çš„æ¯éš»è‚¡ç¥¨**ï¼Œèªªæ˜ï¼š
  * è©²è‚¡ç¥¨æ˜¯å¦åœ¨å°è©±ä¸­è¢«æåŠ
  * å¦‚æœè¢«æåŠï¼Œæ˜¯å¦æœ‰äº¤æ˜“ç™¼ç”Ÿ
  * å¦‚æœæ²’æœ‰è¢«æåŠï¼Œæ˜ç¢ºèªªæ˜æœªæåŠ
"""


def analyze_transactions(
    transcription1: str,
    transcription2: str,
    stock_reference: str,
    model: str,
    ollama_url: str,
    system_message: str,
    temperature: float,
) -> tuple[str, str]:
    """
    Analyze two transcriptions to identify transactions
    
    Returns:
        tuple: (summary_result, json_result)
    """
    try:
        # Validate inputs
        if not transcription1.strip() and not transcription2.strip():
            error_msg = "âŒ éŒ¯èª¤ï¼šè«‹è‡³å°‘æä¾›ä¸€å€‹è½‰éŒ„æ–‡å­—"
            return (error_msg, "")
        
        if not model or not model.strip():
            error_msg = "âŒ éŒ¯èª¤ï¼šè«‹æŒ‡å®šæ¨¡å‹åç¨±"
            return (error_msg, "")
        
        if not ollama_url or not ollama_url.strip():
            error_msg = "âŒ éŒ¯èª¤ï¼šè«‹æŒ‡å®š Ollama URL"
            return (error_msg, "")
        
        # Build the prompt
        # Parse stock reference from JSON format
        stock_ref_text = "ï¼ˆç„¡æä¾›ï¼‰"
        stock_list_for_checking = []
        
        if stock_reference.strip():
            try:
                stock_data = json.loads(stock_reference)
                stocks = stock_data.get("stocks", [])
                
                if stocks:
                    stock_lines = []
                    for idx, stock in enumerate(stocks, 1):
                        # Extract stock information - support both original and corrected versions
                        stock_number = stock.get("stock_number", "")
                        stock_name = stock.get("stock_name", "")
                        corrected_number = stock.get("corrected_stock_number", "")
                        corrected_name = stock.get("corrected_stock_name", "")
                        original_word = stock.get("original_word", "")
                        relevance = stock.get("relevance_score", 0)
                        confidence = stock.get("confidence", "")
                        
                        # Store for explicit checking instruction
                        stock_info = {
                            "original_number": stock_number,
                            "original_name": stock_name,
                            "corrected_number": corrected_number,
                            "corrected_name": corrected_name,
                            "original_word": original_word,
                            "relevance": relevance,
                            "confidence": confidence
                        }
                        stock_list_for_checking.append(stock_info)
                        
                        # Format for display - show both original and corrected if different
                        line_parts = [f"{idx}."]
                        
                        if stock_number:
                            line_parts.append(f"è‚¡ç¥¨ä»£è™Ÿï¼š{stock_number}")
                        if stock_name:
                            line_parts.append(f"è‚¡ç¥¨åç¨±ï¼š{stock_name}")
                        
                        # Show corrected versions if different
                        if corrected_number and corrected_number != stock_number:
                            line_parts.append(f"[ä¿®æ­£ä»£è™Ÿï¼š{corrected_number}]")
                        if corrected_name and corrected_name != stock_name:
                            line_parts.append(f"[ä¿®æ­£åç¨±ï¼š{corrected_name}]")
                        
                        # Show original word from STT if available
                        if original_word:
                            line_parts.append(f"(åŸæ–‡ï¼š{original_word})")
                        
                        # Show relevance score
                        if relevance:
                            line_parts.append(f"(ç›¸é—œåº¦ï¼š{relevance})")
                        
                        stock_lines.append("  ".join(line_parts))
                    
                    if stock_lines:
                        stock_ref_text = "\n".join(stock_lines)
            except json.JSONDecodeError:
                # If JSON parsing fails, treat as plain text (backward compatibility)
                stock_ref_text = stock_reference.strip()
        
        # Build checking instructions based on stock list
        checking_instructions = ""
        if stock_list_for_checking:
            checking_instructions = "\n\n**å¿…é ˆé€ä¸€æª¢æŸ¥ä»¥ä¸‹è‚¡ç¥¨ï¼š**\n"
            for idx, stock in enumerate(stock_list_for_checking, 1):
                orig_number = stock.get("original_number", "")
                orig_name = stock.get("original_name", "")
                corr_number = stock.get("corrected_number", "")
                corr_name = stock.get("corrected_name", "")
                orig_word = stock.get("original_word", "")
                
                # Build comprehensive checking instruction
                check_items = []
                
                # Original versions
                if orig_name:
                    check_items.append(f"ã€Œ{orig_name}ã€")
                if orig_number:
                    check_items.append(f"ã€Œ{orig_number}ã€")
                
                # Corrected versions if different
                if corr_name and corr_name != orig_name:
                    check_items.append(f"ã€Œ{corr_name}ã€(ä¿®æ­£åç¨±)")
                if corr_number and corr_number != orig_number:
                    check_items.append(f"ã€Œ{corr_number}ã€(ä¿®æ­£ä»£è™Ÿ)")
                
                # Original word from STT
                if orig_word:
                    check_items.append(f"ã€Œ{orig_word}ã€(STTåŸæ–‡)")
                
                if check_items:
                    checking_instructions += f"{idx}. æª¢æŸ¥å°è©±ä¸­æ˜¯å¦æåŠï¼š{' æˆ– '.join(check_items)}\n"
        
        prompt = f"""è«‹åˆ†æä»¥ä¸‹å…©å€‹STTæ¨¡å‹ç”Ÿæˆçš„è½‰éŒ„æ–‡å­—ï¼Œè­˜åˆ¥æ˜¯å¦æœ‰è‚¡ç¥¨äº¤æ˜“ç™¼ç”Ÿã€‚

## è½‰éŒ„æ–‡å­— 1ï¼š
{transcription1}

## è½‰éŒ„æ–‡å­— 2ï¼š
{transcription2}

## è‚¡ç¥¨åƒè€ƒè³‡æ–™ï¼ˆéœ€è¦æª¢æŸ¥çš„è‚¡ç¥¨æ¸…å–®ï¼‰ï¼š
{stock_ref_text}
{checking_instructions}

**é‡è¦ä»»å‹™ï¼š**
1. è«‹ä»”ç´°æª¢æŸ¥å°è©±ä¸­æ˜¯å¦æåŠè‚¡ç¥¨åƒè€ƒè³‡æ–™ä¸­åˆ—å‡ºçš„**æ¯ä¸€éš»è‚¡ç¥¨**
2. å°æ–¼æ¯å€‹æåŠçš„è‚¡ç¥¨ï¼Œåˆ¤æ–·æ˜¯å¦æœ‰äº¤æ˜“ç™¼ç”Ÿï¼ˆè²·å…¥/è³£å‡º/æ’éšŠï¼‰
3. ä½¿ç”¨è‚¡ç¥¨åƒè€ƒè³‡æ–™ä¾†é©—è­‰å’Œä¿®æ­£è½‰éŒ„æ–‡å­—ä¸­å¯èƒ½çš„è‚¡ç¥¨ä»£è™Ÿæˆ–åç¨±éŒ¯èª¤
4. åœ¨ overall_summary ä¸­æ˜ç¢ºèªªæ˜ï¼š
   - æª¢æŸ¥äº†å“ªäº›è‚¡ç¥¨
   - å“ªäº›è‚¡ç¥¨åœ¨å°è©±ä¸­è¢«æåŠ
   - å“ªäº›è‚¡ç¥¨æ²’æœ‰è¢«æåŠ
   - å°æ–¼æåŠçš„è‚¡ç¥¨ï¼Œæ˜¯å¦æœ‰äº¤æ˜“ç™¼ç”Ÿ

è«‹æ ¹æ“šä»¥ä¸Šè³‡æ–™ï¼Œä½¿ç”¨çµæ§‹åŒ–æ ¼å¼è¿”å›åˆ†æçµæœã€‚
"""
        
        # Initialize the LLM with structured output
        chat_llm = ChatOllama(
            model=model,
            base_url=ollama_url,
            temperature=temperature,
            format="json",  # Request JSON format
        )
        
        # Prepare messages
        messages = [
            ("system", system_message),
            ("human", prompt),
        ]
        
        # Get response
        print(f"ğŸ” Analyzing transactions with {model}...")
        resp = chat_llm.invoke(messages)
        
        # Extract content
        try:
            response_content = getattr(resp, "content", str(resp))
        except Exception:
            response_content = str(resp)
        
        # Try to parse as structured output
        try:
            result_dict = json.loads(response_content)
            
            # Debug: Print raw JSON response
            print("="*60)
            print("ğŸ” DEBUG: Raw LLM JSON Response:")
            print(json.dumps(result_dict, indent=2, ensure_ascii=False))
            print("="*60)
            
            # Extract the new structure
            transactions = result_dict.get("transactions", [])
            comparison = result_dict.get("transcription_comparison", "")
            overall_summary = result_dict.get("overall_summary", "")
            
            # Create formatted summary result for all transactions
            summary_result = f"""ğŸ“Š äº¤æ˜“åˆ†æçµæœ
{'='*50}

ğŸ“‹ ç¸½å…±è­˜åˆ¥åˆ° {len(transactions)} å€‹äº¤æ˜“

"""
            
            if len(transactions) == 0:
                summary_result += "âŒ æ²’æœ‰è­˜åˆ¥åˆ°ä»»ä½•äº¤æ˜“\n\n"
            else:
                for idx, tx in enumerate(transactions, 1):
                    tx_type = tx.get("transaction_type", "none")
                    tx_conf = tx.get("confidence_score", 0.0)
                    tx_code = tx.get("stock_code", "") or "N/A"
                    tx_name = tx.get("stock_name", "") or "N/A"
                    tx_qty = tx.get("quantity", "") or "N/A"
                    tx_price = tx.get("price", "") or "N/A"
                    tx_exp = tx.get("explanation", "")
                    
                    summary_result += f"""{'â”€'*50}
äº¤æ˜“ #{idx}
{'â”€'*50}
ğŸ”– äº¤æ˜“é¡å‹: {tx_type}
â­ ç½®ä¿¡åº¦åˆ†æ•¸: {tx_conf} / 2.0
ğŸ“ˆ è‚¡ç¥¨ä»£è™Ÿ: {tx_code}
ğŸ¢ è‚¡ç¥¨åç¨±: {tx_name}
ğŸ”¢ æ•¸é‡: {tx_qty}
ğŸ’° åƒ¹æ ¼: {tx_price}

ğŸ“ åˆ†æèªªæ˜:
{tx_exp}

"""
            
            summary_result += f"""{'='*50}
ğŸ”„ è½‰éŒ„æ¯”è¼ƒ:
{comparison}

{'='*50}
ğŸ“„ æ•´é«”æ‘˜è¦:
{overall_summary}
"""
            
            # Format JSON result with proper indentation
            json_result = json.dumps(result_dict, indent=2, ensure_ascii=False)
            
            return (summary_result, json_result)
            
        except json.JSONDecodeError:
            # If not valid JSON, return the raw response
            error_msg = f"âš ï¸ æ¨¡å‹è¿”å›éçµæ§‹åŒ–è¼¸å‡ºï¼š\n\n{response_content}"
            return (error_msg, response_content)
        
    except Exception as e:
        error_msg = f"âŒ éŒ¯èª¤: {str(e)}\n\nè©³ç´°ä¿¡æ¯:\n{traceback.format_exc()}"
        return (error_msg, "")


def create_transaction_analysis_tab():
    """Create and return the Transaction Analysis tab"""
    with gr.Tab("ğŸ“Š Transaction Analysis"):
        gr.Markdown(
            """
            ### äº¤æ˜“åˆ†æ - æ¯”è¼ƒå…©å€‹STTè½‰éŒ„ä¸¦è­˜åˆ¥äº¤æ˜“
            ä½¿ç”¨Pydanticçµæ§‹åŒ–è¼¸å‡ºè­˜åˆ¥æ‰€æœ‰è‚¡ç¥¨äº¤æ˜“ï¼ˆè²·å…¥/è³£å‡º/æ’éšŠï¼‰ä¸¦è©•ä¼°ç½®ä¿¡åº¦ï¼ˆ0-2åˆ†ï¼‰
            
            **æ”¯æŒåŠŸèƒ½ï¼š**
            - âœ… è­˜åˆ¥å¤šå€‹äº¤æ˜“ï¼ˆä¸€å€‹å°è©±ä¸­å¯èƒ½æœ‰å¤šç­†äº¤æ˜“ï¼‰
            - âœ… è­˜åˆ¥å–®å€‹äº¤æ˜“
            - âœ… è­˜åˆ¥ç„¡äº¤æ˜“çš„å°è©±
            - âœ… é€ä¸€æª¢æŸ¥è‚¡ç¥¨åƒè€ƒè³‡æ–™ä¸­çš„æ‰€æœ‰è‚¡ç¥¨ï¼ˆåŒ…æ‹¬åŸå§‹å’Œä¿®æ­£ç‰ˆæœ¬ï¼‰
            - âœ… ä½¿ç”¨è‚¡ç¥¨åƒè€ƒè³‡æ–™ä¾†é©—è­‰å’Œä¿®æ­£STTèª¤å·®
            - âœ… æ”¯æŒ original_wordã€corrected_stock_number/nameã€relevance_score ç­‰å­—æ®µ
            - âœ… è‡ªå‹•è­˜åˆ¥STTèª¤å·®ï¼ˆå¦‚"ä¸€ç™¾ä¸€ä¸‰å…«"â†’"18138"ã€"é‡‘ç¢Ÿ"â†’"é‡‘è¶åœ‹éš›"ï¼‰
            """
        )
        
        with gr.Row():
            with gr.Column(scale=1):
                gr.Markdown("#### è¼¸å…¥è¨­å®š")
                
                transcription1_box = gr.Textbox(
                    label="è½‰éŒ„æ–‡å­— 1 (STT Model 1)",
                    placeholder="è«‹è¼¸å…¥ç¬¬ä¸€å€‹STTæ¨¡å‹çš„è½‰éŒ„çµæœ...",
                    lines=10,
                )
                
                transcription2_box = gr.Textbox(
                    label="è½‰éŒ„æ–‡å­— 2 (STT Model 2)",
                    placeholder="è«‹è¼¸å…¥ç¬¬äºŒå€‹STTæ¨¡å‹çš„è½‰éŒ„çµæœ...",
                    lines=10,
                )
                
                stock_reference_box = gr.Textbox(
                    label="è‚¡ç¥¨åƒè€ƒè³‡æ–™ (Stock References - JSON Format)",
                    placeholder='{\n  "stocks": [\n    {\n      "stock_number": "00700",\n      "stock_name": "é¨°è¨Š",\n      "corrected_stock_number": "00700",\n      "corrected_stock_name": "é¨°è¨Šæ§è‚¡",\n      "original_word": "é¨°è¨Š",\n      "relevance_score": 1.0,\n      ...\n    }\n  ]\n}',
                    lines=5,
                    info="è¼¸å…¥JSONæ ¼å¼çš„è‚¡ç¥¨åƒè€ƒè³‡æ–™ã€‚ç³»çµ±å°‡è‡ªå‹•æå–æ‰€æœ‰è‚¡ç¥¨çš„ä»£è™Ÿ(stock_number)ã€åç¨±(stock_name)ã€ä¿®æ­£ç‰ˆæœ¬(corrected_*)åŠSTTåŸæ–‡(original_word)é€²è¡Œåˆ†æã€‚",
                )
                
                gr.Markdown("#### LLM è¨­å®š")
                
                with gr.Row():
                    model_dropdown = gr.Dropdown(
                        choices=MODEL_OPTIONS,
                        value=DEFAULT_MODEL,
                        label="æ¨¡å‹",
                        allow_custom_value=True,
                    )
                    temperature_slider = gr.Slider(
                        minimum=0.0,
                        maximum=2.0,
                        value=0.3,
                        step=0.1,
                        label="Temperature",
                        info="è¼ƒä½çš„æº«åº¦æœƒè®“çµæœæ›´ç¢ºå®š",
                    )
                
                ollama_url_box = gr.Textbox(
                    label="Ollama URL",
                    value=DEFAULT_OLLAMA_URL,
                    placeholder="http://localhost:11434",
                )
                
                system_message_box = gr.Textbox(
                    label="ç³»çµ±è¨Šæ¯ (System Message)",
                    value=DEFAULT_SYSTEM_MESSAGE,
                    lines=8,
                )
                
                analyze_btn = gr.Button(
                    "ğŸš€ é–‹å§‹åˆ†æäº¤æ˜“",
                    variant="primary",
                    size="lg"
                )
            
            with gr.Column(scale=1):
                gr.Markdown("#### åˆ†æçµæœ")
                
                # Summary Result Textbox (all transactions)
                summary_result_box = gr.Textbox(
                    label="ğŸ“Š å®Œæ•´çµæœæ‘˜è¦ (All Transactions)",
                    lines=15,
                    interactive=False,
                    show_copy_button=True,
                )
                
                # JSON Result Textbox (raw output)
                json_result_box = gr.Textbox(
                    label="ğŸ“‹ Pydantic JSON è¼¸å‡º (JSON Output)",
                    lines=15,
                    interactive=False,
                    show_copy_button=True,
                )
        
        # Connect the button
        analyze_btn.click(
            fn=analyze_transactions,
            inputs=[
                transcription1_box,
                transcription2_box,
                stock_reference_box,
                model_dropdown,
                ollama_url_box,
                system_message_box,
                temperature_slider,
            ],
            outputs=[
                summary_result_box,
                json_result_box,
            ],
        )

